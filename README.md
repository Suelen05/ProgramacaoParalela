# Estimativa de œÄ com o M√©todo de Monte Carlo usando pthreads (C)

## üéØ Objetivo do Reposit√≥rio

Este projeto tem como objetivo implementar o c√°lculo de œÄ (Pi) utilizando o **m√©todo de Monte Carlo**, nas vers√µes **sequencial** e **paralela** (usando a biblioteca `pthread.h`).

O projeto foi desenvolvido como parte da disciplina de **Computa√ß√£o de Alto Desempenho** da **Universidade do Vale do Rio dos Sinos (UNISINOS)**.

---

## üìå Breve explica√ß√£o do M√©todo de Monte Carlo

O m√©todo de Monte Carlo √© uma t√©cnica probabil√≠stica utilizada para resolver problemas matem√°ticos atrav√©s da gera√ß√£o de n√∫meros aleat√≥rios.

Neste caso, o c√°lculo de œÄ √© baseado na raz√£o entre a √°rea de um **quarto de c√≠rculo de raio 1** e um **quadrado de lado 1**, utilizando a seguinte f√≥rmula:

\[
\pi \approx 4 \times \left( \frac{\text{N¬∫ de pontos dentro do c√≠rculo}}{\text{N¬∫ total de pontos gerados}} \right)
\]

O algoritmo consiste em:

1. Gerar um grande n√∫mero de pontos aleat√≥rios dentro de um quadrado.
2. Verificar quantos desses pontos caem dentro do c√≠rculo.
3. Aplicar a f√≥rmula acima para obter a estimativa de œÄ.

---

## üñ•Ô∏è Ambiente de Testes

Todos os testes de desempenho foram realizados em um ambiente **virtualizado** utilizando o **VirtualBox**, rodando o sistema **Kali Linux (amd64)**.

### Configura√ß√£o da m√°quina virtual (VM)

- **Sistema Operacional:** Kali Linux (amd64)
- **CPUs alocadas:** 24 CPUs virtuais
- **Mem√≥ria RAM alocada:** 107.284 MB (~104,8 GB)

### Configura√ß√£o da m√°quina host (processador f√≠sico)

- **Modelo de CPU:** Intel com arquitetura h√≠brida (Performance e Efficient cores)
- **N√∫mero de n√∫cleos f√≠sicos:** 24 n√∫cleos (8 Performance-cores + 16 Efficient-cores)
- **Total de threads:** 32
- **Frequ√™ncia Turbo M√°xima:** At√© 5.80 GHz  
*(Especifica√ß√µes detalhadas est√£o ilustradas na imagem abaixo)*

---

## üìÇ Estrutura do Reposit√≥rio

MonteCarlo_PI/

- pi.c --> Programa sequencial
- pi_thread --> Programa em paralelo

- resultados --> Pasta com os resultados de execu√ß√£o (prints de sa√≠da)

  - 1.000.000.000 --> Resultados com 1 Bilh√£o de pontos
  - 10.000.000.000 --> Resultados com 10 Bilh√µes de pontos
- executaveis --> Arquivos .exe gerados (compilados), separados por quantidade de pontos
  - 1.000.000.000 --> Resultados com 1 Bilh√£o de pontos
  - 10.000.000.000 --> Resultados com 10 Bilh√µes de pontos
- README.md --> Este arquivo

---

## ‚öôÔ∏è Compila√ß√£o e Execu√ß√£o

### ‚úÖ Compilando os c√≥digos

#### Vers√£o Sequencial

```bash
gcc -o pi.exe pi.c 
```

#### Vers√£o Paralela:

```bash
gcc -o pi_thread.exe pi_thread.c -lpthread
```

### ‚úÖ Executando os programas

#### Vers√£o Sequencial

```bash
./pi.exe
```

#### Vers√£o Paralela

```bash
./pi_thread.exe
```

---

## üìù Como alterar a quantidade de pontos e de threads

### ‚úÖ Alterando o n√∫mero de pontos a serem gerados (precis√£o do c√°lculo)

Em ambos os c√≥digos (sequencial e paralelo), o n√∫mero total de pontos est√° definido em uma constante, geralmente chamada:

``` c
#define NUM_PONTOS 1000000000  // Exemplo: 1 bilh√£o de pontos
```

Se quiser mudar, basta alterar o valor dessa constante para o n√∫mero desejado. Exemplo:

``` c
#define NUM_PONTOS 10000000000  // Agora com 10 bilh√µes de pontos
```

Depois de alterar, recompile o c√≥digo.

### ‚úÖ Alterando o n√∫mero de threads (apenas no c√≥digo paralelo)

No c√≥digo com pthreads, o n√∫mero de threads tamb√©m est√° definido por uma constante:

``` c
#define NUM_THREADS 4  // Exemplo: 4 threads
```

Se quiser testar com outra quantidade (exemplo: 8, 16, 32 threads), √© s√≥ alterar o valor:

``` c
#define NUM_THREADS 16  // Agora com 16 threads
```

Depois de alterar, recompile o c√≥digo.

### ‚úÖ Resumo

| Modifica√ß√£o          | Onde alterar                                           | Precisa recompilar? |
| -------------------- | ------------------------------------------------------ | ------------------- |
| Quantidade de pontos | Valor da constante `NUM_PONTOS`                        | ‚úÖ Sim               |
| N√∫mero de threads    | Valor da constante `NUM_THREADS` (somente no paralelo) | ‚úÖ Sim               |


## üìä An√°lise Detalhada dos Resultados

Para cada configura√ß√£o de n√∫mero de threads (1, 2, 4, 8, 16 e 32 threads), foram realizadas **8 execu√ß√µes separadas**, tanto com **1 bilh√£o de pontos (10‚Åπ)** quanto com **10 bilh√µes de pontos (10¬π‚Å∞)**.

Isso permitiu obter uma m√©dia mais confi√°vel dos tempos de execu√ß√£o, reduzindo o impacto de varia√ß√µes naturais de desempenho causadas por processos de sistema, overhead de virtualiza√ß√£o e limita√ß√µes do hardware.

---

### üìå Tempos M√©dios Obtidos (em segundos)

#### ‚úÖ 1 Bilh√£o de Pontos

| N¬∫ de Threads | M√©dia de Tempo (s) |
|---|---|
| 1 | 27,23 |
| 2 | 11,61 |
| 4 | 14,97 |
| 8 | 39,34 |
| 16 | 46,10 |
| 32 | 49,49 |

---

#### ‚úÖ 10 Bilh√µes de Pontos

| N¬∫ de Threads | M√©dia de Tempo (s) |
|---|---|
| 1 | 267,56 |
| 2 | 117,58 |
| 4 | 132,10 |
| 8 | 168,04 |
| 16 | 244,14 |
| 32 | 393,79 |

---

### üìå Observa√ß√µes Principais

- **Ganho de desempenho significativo ao passar de 1 para 2 threads**, com speedups superiores a 2x.
- **A partir de 4 threads**, a efici√™ncia diminuiu consideravelmente, indicando que o programa passou a sofrer com overhead de sincroniza√ß√£o (causado principalmente pelo uso de mutex) e limita√ß√µes da m√°quina virtual.
- Os **tempos de execu√ß√£o come√ßaram a piorar com 8 threads ou mais**, mostrando claramente os efeitos negativos de:
  - Conten√ß√£o no acesso ao mutex.
  - Overhead da cria√ß√£o e sincroniza√ß√£o de muitas threads.
  - Limita√ß√µes de performance t√≠picas de ambientes virtualizados.

---

### üìå Influ√™ncia do Ambiente de Testes

> √â importante destacar que **todos os testes foram executados em um ambiente virtualizado (VirtualBox)**, rodando o sistema **Kali Linux (amd64)**, com **24 CPUs virtuais alocadas** e **107.284 MB (~104,8 GB) de mem√≥ria**.

Al√©m disso, a m√°quina f√≠sica (host) utilizada para as execu√ß√µes possui o seguinte processador:

- **Modelo de CPU Host:** Intel Core i9-13900K (24 n√∫cleos f√≠sicos: 8 Performance-cores + 16 Efficient-cores / Total de 32 threads).
- **Frequ√™ncia Turbo M√°xima:** At√© 5.80 GHz.

Essa virtualiza√ß√£o certamente introduziu um overhead adicional e influenciou os resultados de escalabilidade.

---

### üìå Conclus√£o

Apesar das limita√ß√µes de ambiente, o projeto demonstrou:

‚úÖ Ganhos reais de desempenho para at√© 2 threads.  
‚úÖ Impacto pr√°tico de problemas como **conten√ß√£o de mutex** e **overhead de virtualiza√ß√£o**.  
‚úÖ Import√¢ncia de ajustar o n√∫mero de threads de acordo com a arquitetura e ambiente de execu√ß√£o.

Essa an√°lise contribuiu para o entendimento pr√°tico dos conceitos de **paralelismo, sincroniza√ß√£o e escalabilidade**.

## üìå Observa√ß√£o Final

Esse reposit√≥rio √© para fins acad√™micos e pode ser adaptado ou otimizado em implementa√ß√µes futuras (exemplo: uso de t√©cnicas de redu√ß√£o ou migra√ß√£o para bibliotecas como OpenMP ou MPI).
